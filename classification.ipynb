{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from warnings import filterwarnings\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preperation\n",
    "To prepare our data we'll have to first create our labels and import our images, then split it into training and testing data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Preperation\n",
    "To prepare our data we'll have to first create our labels and import our images, then split it into training and testing data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append all images to lists\n",
    "X_train = []\n",
    "y_train = []\n",
    "image_size = 150\n",
    "for i in labels:\n",
    "    folderPath = os.path.join('../input/brain-tumor-classification-mri','Training',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size, image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)\n",
    "        \n",
    "for i in labels:\n",
    "    folderPath = os.path.join('../input/brain-tumor-classification-mri','Testing',i)\n",
    "    for j in tqdm(os.listdir(folderPath)):\n",
    "        img = cv2.imread(os.path.join(folderPath,j))\n",
    "        img = cv2.resize(img,(image_size,image_size))\n",
    "        X_train.append(img)\n",
    "        y_train.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure to look at sample image\n",
    "k=0\n",
    "fig, ax = plt.subplots(1,4,figsize=(20,20))\n",
    "fig.text(s='Example Image From Each Label',\n",
    "         size=18,\n",
    "         fontweight='bold',\n",
    "         fontname='monospace',\n",
    "         color='black',\n",
    "         y=0.62,\n",
    "         x=0.4,\n",
    "         alpha=0.8)\n",
    "\n",
    "# upload random image\n",
    "import random\n",
    "for i in labels:\n",
    "    j=random.randint(0, len(X_train)-1)\n",
    "    while True :\n",
    "        if y_train[j]==i:\n",
    "            ax[k].imshow(X_train[j])\n",
    "            ax[k].set_title(y_train[j])\n",
    "            ax[k].axis('off')\n",
    "            k+=1\n",
    "            break\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "X_train, y_train = shuffle(X_train,y_train, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training and testing split from our data\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train,test_size=0.1,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert labels to categorical numbers\n",
    "y_train_new = []\n",
    "for i in y_train:\n",
    "    y_train_new.append(labels.index(i))\n",
    "y_train = y_train_new\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "\n",
    "y_test_new = []\n",
    "for i in y_test:\n",
    "    y_test_new.append(labels.index(i))\n",
    "y_test = y_test_new\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning\n",
    "To approach this image classifcation problem we'll use transfer learning, applying the weights on a previously successful model to our current one. The one I've selected is EfficientNetB0 as it isn't as computationally demanding and is well trained on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import EfficientNetB0 weights\n",
    "effnet = EfficientNetB0(weights='imagenet',\n",
    "                        include_top=False,\n",
    "                        input_shape=(image_size,image_size,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply weights to our model\n",
    "model = effnet.output\n",
    "\n",
    "# global average for easier computation\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "\n",
    "# dropout to avoid overfitting\n",
    "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "\n",
    "# output layer\n",
    "model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=effnet.input, outputs = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model: \"functional_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = 'Adam',\n",
    "              metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get callbacks to keep up with model\n",
    "tensorboard = TensorBoard(log_dir = 'logs')\n",
    "checkpoint = ModelCheckpoint(\"effnet.keras\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n",
    "                              mode='auto',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on our data\n",
    "history = model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n",
    "                   callbacks=[tensorboard,checkpoint,reduce_lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation\n",
    "To evaluate our model's performance we'll look at how its accuracy and loss change over time, as well as its confusion matrix to ensure it's making the right classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at chart of accuracy & loss\n",
    "filterwarnings('ignore')\n",
    "\n",
    "epochs = [i for i in range(12)]\n",
    "fig, ax = plt.subplots(1,2,figsize=(14,7))\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "fig.text(0.5, 0.9, 'Performance Over Epochs',\n",
    "         ha='center',\n",
    "         fontsize=20,\n",
    "         fontweight='bold')\n",
    "\n",
    "sns.despine()\n",
    "ax[0].plot(epochs, train_acc, marker='o',color='blue',\n",
    "           label = 'Training')\n",
    "ax[0].plot(epochs, val_acc, marker='o',color='red',\n",
    "           label = 'Validation')\n",
    "ax[0].legend(frameon=False)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "\n",
    "sns.despine()\n",
    "ax[1].plot(epochs, train_loss, marker='o',color='blue',\n",
    "           label ='Training')\n",
    "ax[1].plot(epochs, val_loss, marker='o',color='red',\n",
    "           label = 'Validation')\n",
    "ax[1].legend(frameon=False)\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predicted values to compare vs actual ones\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_test_new = np.argmax(y_test,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "fig,ax=plt.subplots(1,1,figsize=(14,7))\n",
    "sns.heatmap(confusion_matrix(y_test_new,pred),\n",
    "            ax=ax,xticklabels=labels,\n",
    "            yticklabels=labels,\n",
    "            annot=True,\n",
    "            cmap='Blues',\n",
    "            alpha=0.7,\n",
    "            linewidths=2,\n",
    "            linecolor='black',\n",
    "            cbar=False)\n",
    "fig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',\n",
    "             fontname='monospace',color='black',y=0.92,x=0.28,alpha=0.8)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
